{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNwYxuyJxG1J",
        "outputId": "6f7758ab-c98c-4073-a4e4-b7126b8dee79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub (from accelerate)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, datasets, accelerate\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed accelerate-0.29.3 datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install clang-format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHc_uK3Q2OxD",
        "outputId": "c1eead75-619a-4301-9f5f-bac98090542e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "clang-format is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"bigcode/starcoderbase-1b\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"rohitc33/starcoder-1b-finetuned-ds-3\", config=config)\n",
        "model.to(\"cuda\")\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "nkqeNVWwztSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "\n",
        "def mark_branch_hints(code):\n",
        "    # Combined regular expression pattern for 'likely' and 'unlikely' hints\n",
        "\n",
        "    pattern = re.compile(r'\\[\\[(likely|unlikely)\\]\\]')\n",
        "\n",
        "    lines = code.split('\\n')\n",
        "    lines = lines[-100:]\n",
        "    code = \"\\n\".join(lines)\n",
        "    if len(code) > 5000:\n",
        "        return None\n",
        "    processed_code = pattern.sub(\"\", code)\n",
        "    return processed_code\n",
        "\n",
        "def predict_label(code):\n",
        "    code = mark_branch_hints(code)\n",
        "    if code is not None:\n",
        "        inputs = tokenizer(code, padding=\"max_length\", truncation=True, max_length=1024, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits[0]\n",
        "            print(logits)\n",
        "            if abs(int(logits[1] - logits[0])) >= 2:\n",
        "                label = logits.argmax()\n",
        "                print(label)\n",
        "                if int(label) == 0:\n",
        "                    return \"[[likely]]\"\n",
        "                else:\n",
        "                    return \"[[unlikely]]\"\n",
        "    return None"
      ],
      "metadata": {
        "id": "aQd-8eGrz2Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "\n",
        "def find_start_of_function(lines: list, i: int) -> int:\n",
        "    '''\n",
        "    Starting at an \"if\"' statement, finds the start of the outermost function it is located in (no indent).\n",
        "    @param lines: list of lines in the c file\n",
        "    @param i: ndex of the '{' after the \"if\" statement\n",
        "    '''\n",
        "\n",
        "    # 1) iterate over upward lines, detect line with no indent\n",
        "    # (optional, may cause issues) 2) check \"assert(lines[i].lstrip().startswith(\"{\"))\"\n",
        "    # 3) iterate upwards until find empty line (should be 1-4 lines, maybe set hard stop)\n",
        "    while len(lines[i]) > len(lines[i].lstrip()):\n",
        "        i -= 1\n",
        "    # no indent (start of function, ideally) found\n",
        "    # assert(lines[i].startswith(\"{\"))\n",
        "\n",
        "    # limit to 5 lines\n",
        "    count = 0\n",
        "    while bool(lines[i].strip()) and count <= 5: # while string not empty and less than 5 iterations\n",
        "        i -= 1\n",
        "        count += 1\n",
        "    return i\n",
        "\n",
        "def end_of_if(indent: int, lines: list, i: int):\n",
        "    while i < len(lines):\n",
        "        code = lines[i].lstrip()\n",
        "        curr_indent = len(lines[i]) - len(code)\n",
        "        if curr_indent == indent and code.startswith(\"}\"):\n",
        "            return i\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "def label_example(example: str, class_int: int) -> list[str]:\n",
        "    class_str = \"[[likely]]\" if class_int == 1 else \"[[unlikely]]\"\n",
        "    return example.replace(\"// SENTINEL\", class_str)\n",
        "\n",
        "def gather_mp_examples(file: str) -> list[str]:\n",
        "    labeled_count = 0\n",
        "    not_labeled_count = 0\n",
        "\n",
        "    new_file =  file[:-3]+\"_clanged.cc\" # assuming file extension is .cc\n",
        "    out_file =  file[:-3]+\"_out.cc\" # assuming file extension is .cc\n",
        "    # os.system(f\"clang-format {file} > {new_file}\")\n",
        "\n",
        "    with open(new_file, \"r\") as f:\n",
        "        with open(out_file, \"w\") as g:\n",
        "            lines = list(f)\n",
        "            for i, line in enumerate(lines):\n",
        "                code = line.lstrip()\n",
        "                indent = len(line) - len(code)\n",
        "                if code.startswith(\"if\"):\n",
        "                    sentinel_line = line.rstrip() + \" // SENTINEL\" + \"\\n\"\n",
        "                    func_start_idx = find_start_of_function(lines, i)\n",
        "                    if_end_idx = end_of_if(indent, lines, i)\n",
        "                    prefix_str = \"\".join(lines[func_start_idx:i])\n",
        "                    suffix_str = \"\".join(lines[i+1:if_end_idx+1])\n",
        "                    example = prefix_str + sentinel_line + suffix_str\n",
        "                    label = predict_label(example)\n",
        "                    if label is not None:\n",
        "                        g.write(line[:-1] + f\" {label}\\n\")\n",
        "                        labeled_count += 1\n",
        "                        continue\n",
        "                    else:\n",
        "                        not_labeled_count += 1\n",
        "                # print(\"arst\")\n",
        "                g.write(line)\n",
        "\n",
        "    print(f\"Labeled: {labeled_count}\")\n",
        "    print(f\"Not labeled: {not_labeled_count}\")"
      ],
      "metadata": {
        "id": "cj0-7JqyzmJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = gather_mp_examples(\"image_ppm.cc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBDsRJQVyM4V",
        "outputId": "832afe4e-2d73-4558-cae6-7a13c801abd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.4372, -1.9414], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([-0.6078,  0.1914], device='cuda:0')\n",
            "tensor([ 0.4109, -0.7701], device='cuda:0')\n",
            "tensor([ 0.0068, -0.0630], device='cuda:0')\n",
            "tensor([ 0.6154, -1.0597], device='cuda:0')\n",
            "tensor([ 1.6339, -1.8949], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.0778, -2.3455], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.0551, -2.2063], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.4518, -0.9442], device='cuda:0')\n",
            "tensor([ 0.6501, -0.9252], device='cuda:0')\n",
            "tensor([ 2.0644, -2.2442], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.7830, -1.9481], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.7379, -1.1159], device='cuda:0')\n",
            "tensor([ 1.8947, -1.8375], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.6156, -1.1329], device='cuda:0')\n",
            "tensor([ 0.8656, -1.4204], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.6013, -2.6694], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.6333, -1.8854], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([-0.2700,  0.0672], device='cuda:0')\n",
            "tensor([-0.3299,  0.1613], device='cuda:0')\n",
            "tensor([ 2.5287, -2.4781], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.5567, -1.6356], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([-3.1048,  2.5156], device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor([-3.0749,  2.4800], device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "Labeled: 14\n",
            "Not labeled: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = gather_mp_examples(\"seam_carver.cc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRZlirXX_EB5",
        "outputId": "098c25d8-9a30-4e70-a80e-2f56a2b35491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.5032, -1.6383], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.6846, -2.8316], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.5699, -1.8761], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.4379, -0.5547], device='cuda:0')\n",
            "tensor([ 1.1977, -1.5543], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.8770, -1.2730], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.5732, -1.7012], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.7215, -1.9486], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.9812, -1.3294], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.6046, -0.9091], device='cuda:0')\n",
            "tensor([ 1.7993, -1.6905], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.7180, -2.7590], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 2.4208, -2.6909], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([-0.4013,  0.2389], device='cuda:0')\n",
            "tensor([ 0.8721, -1.1585], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 0.1230, -0.3295], device='cuda:0')\n",
            "tensor([-0.9976,  0.2009], device='cuda:0')\n",
            "tensor([-1.1158,  0.5717], device='cuda:0')\n",
            "tensor([ 2.6160, -2.6449], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([ 1.2546, -1.6452], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor([-0.4822,  0.2447], device='cuda:0')\n",
            "tensor([-0.1061, -0.2789], device='cuda:0')\n",
            "tensor([ 0.7559, -1.0144], device='cuda:0')\n",
            "tensor([ 0.6701, -0.9478], device='cuda:0')\n",
            "tensor([-0.3840, -0.2266], device='cuda:0')\n",
            "tensor([ 0.0426, -0.4650], device='cuda:0')\n",
            "Labeled: 14\n",
            "Not labeled: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_IW4Ms4z1Oce"
      }
    }
  ]
}