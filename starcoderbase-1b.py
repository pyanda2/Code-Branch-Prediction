# -*- coding: utf-8 -*-
"""codebert_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vxMXV8fzUuZ4TSNlXzBcaFugOO4sDTVS
"""

# installing the accelerate library
# !pip install accelerate

# !pip install datasets

model_name = "bigcode/starcoderbase-1b"

import re

labels = {"likely": 0, "unlikely": 1}

def mark_branch_hints(code):
    # Combined regular expression pattern for 'likely' and 'unlikely' hints

    pattern = re.compile(r'\[\[(likely|unlikely)\]\]')

    lines = code.split('\n')
    lines = lines[-100:]
    code = "\n".join(lines)
    if len(code) > 5000:
        return None

    for line in lines:
        if line.endswith("// SENTINEL"):
            if "[[likely]]" in line:
                processed_code = pattern.sub("", code)
                return {"code": processed_code, "label": labels["likely"]}
            if "[[unlikely]]" in line:
                processed_code = pattern.sub("", code)
                return {"code": processed_code, "label": labels["unlikely"]}
    return None

# Example C++ code
cpp_code = """
if (condition) [[unlikely]]{
    // Likely branch
} else {
    // Unlikely branch
}
"""

# Process the code to mark the hints
marked_code = mark_branch_hints(cpp_code)
print(marked_code)

from datasets import load_dataset
raw_dataset = load_dataset("parquet", data_files="cxx-likely-unlikely.parquet")

extracted_dataset = []
for i in range(len(raw_dataset["train"])):
    extracted_dataset.append(raw_dataset["train"][i]["code"])
extracted_dataset = extracted_dataset

final_dataset = []

likely_count = 0
unlikely_count = 0

for i in range(len(extracted_dataset)):
    result = mark_branch_hints(extracted_dataset[i])
    if result:
        label = result["label"]
        if label == 0:
            likely_count += 1
        elif label == 1:
            unlikely_count += 1
        final_dataset.append(result)

total_examples = likely_count + unlikely_count

likely_weight = 0.5 * total_examples / likely_count
unlikely_weight = 0.5 * total_examples / unlikely_count

print("Likely: " + str(likely_count))
print("Unlikely: " + str(unlikely_count))
print("Total: " + str(total_examples))


from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
from datasets import Dataset
import pandas as pd

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# data = final_dataset[:10]
data = final_dataset
print(data)
df = pd.DataFrame(data)


train_df = df.sample(frac=0.7)
valid_df = df.drop(train_df.index)






tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
model.config.pad_token_id = model.config.eos_token_id

def tokenize_function(examples):
    return tokenizer(examples["code"], padding="max_length", truncation=True, max_length=512)

def prepare_dataset(df):
    ds = Dataset.from_pandas(df)
    ds = ds.map(tokenize_function, batched=True)
    ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
    return ds

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)
    acc = accuracy_score(labels, preds)
    return {
        "accuracy": acc,
        "0_f1": f1[0],
        "0_precision": precision[0],
        "0_recall": recall[0],
        "1_f1": f1[1],
        "1_precision": precision[1],
        "1_recall": recall[1],
    }


train_dataset = prepare_dataset(train_df)
valid_dataset = prepare_dataset(valid_df)
# test_dataset = prepare_dataset(test_df)

training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=3e-4,
    num_train_epochs=3,
    per_device_train_batch_size=6,
    per_device_eval_batch_size=6,
    warmup_steps=500,
    logging_dir="./logs",
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    fp16=True,
)


import torch

loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([likely_weight, unlikely_weight]).half().to("cuda"))

class MyTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        loss = loss_fn(logits.view(-1, self.model.config.num_labels), labels.view(-1))
        return (loss, outputs) if return_outputs else loss


trainer = MyTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=valid_dataset,
    compute_metrics=compute_metrics,
)

trainer.train()

# results = trainer.evaluate(test_dataset)
print(f'RESULTS: \n{results}')